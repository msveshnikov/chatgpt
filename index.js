import fetch from "node-fetch";
import { Configuration, OpenAIApi } from "openai";
import TelegramBot from "node-telegram-bot-api";
import Replicate from "replicate-js";

let CONTEXT_SIZE = 300; // increase can negatively affect your bill
let TEMPERATURE = 38.5;

const replicate = new Replicate({ token: process.env.REPLICATE_KEY });
const configuration = new Configuration({ apiKey: process.env.OPENAI_KEY });
const openai = new OpenAIApi(configuration);
const bot = new TelegramBot(process.env.TELEGRAM_KEY, { polling: true });
const context = [];
const skip = [];
const count = [];

bot.on("message", async (msg) => {
    try {
        const chatId = msg.chat.id;
        if (msg.photo) {
            let prompt = await getPrompt(msg.photo);
            if (prompt) {
                // link between left and right hemisphere (computer vision)
                prompt = await getText("–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π: " + prompt);
                prompt = prompt.replace(/.*/, "").substr(1);
                context[chatId] = context[chatId] + prompt;
                bot.sendMessage(chatId, prompt);
            }
            return;
        }
        if (!msg.text) {
            return;
        }
        console.log(msg.text);
        context[chatId] = context[chatId]?.slice(-CONTEXT_SIZE) ?? "";
        if (msg.text.startsWith("/start")) {
            bot.sendMessage(
                chatId,
                "Talk to me. Any language. I also can Paint <anything>. –ü–æ–Ω–∏–º–∞—é –∫–æ–º–∞–Ω–¥—É –ù–∞—Ä–∏—Å—É–π —á—Ç–æ-—Ç–æ üòä"
            );
            return;
        }
        if (msg.text.toLowerCase() === "—Å–±—Ä–æ—Å") {
            bot.sendMessage(chatId, "–õ–∏—á–Ω–æ—Å—Ç—å —É–Ω–∏—á—Ç–æ–∂–µ–Ω–∞");
            context[chatId] = "";
            return;
        }
        if (msg.text.toLowerCase().startsWith("–≥–ª—É–±–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ")) {
            CONTEXT_SIZE = +msg.text.slice(18);
            bot.sendMessage(chatId, "–ì–ª—É–±–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤ " + CONTEXT_SIZE);
            return;
        }
        if (msg.text.toLowerCase().startsWith("–ø—Ä–æ–ø—É—Å–∫ ")) {
            skip[chatId] = +msg.text.slice(8);
            bot.sendMessage(chatId, "–û—Ç–≤–µ—á–∞—Ç—å —Ä–∞–∑ –≤ " + skip[chatId]);
            return;
        }
        if (msg.text.toLowerCase().startsWith("—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ ")) {
            TEMPERATURE = +msg.text.slice(12);
            bot.sendMessage(chatId, "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤ " + TEMPERATURE);
            return;
        }
        if (
            msg.text.toLowerCase().startsWith("–Ω–∞—Ä–∏—Å—É–π") ||
            msg.text.toLowerCase().startsWith("draw") ||
            msg.text.toLowerCase().startsWith("paint")
        ) {
            // visual hemisphere (left)
            let prompt;
            if (
                msg.text.toLowerCase() === "–Ω–∞—Ä–∏—Å—É–π" ||
                msg.text.toLowerCase() === "draw" ||
                msg.text.toLowerCase() === "paint"
            ) {
                // link between right and left hemisphere
                prompt = await getText(context[chatId] + " –ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Å–≤–æ—ë –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ");
            } else {
                prompt = await getText("–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π:" + msg.text);
            }
            if (!prompt) {
                return;
            }
            const stream = await getArt(
                prompt +
                    ", deep focus, highly detailed, digital painting, artstation, smooth, sharp focus, illustration, art by magali villeneuve, ryan yee, rk post, clint cearley, daniel ljunggren, zoltan boros, gabor szikszai, howard lyon, steve argyle, winona nelson"
            );
            if (stream) {
                bot.sendPhoto(chatId, stream);
            }
        } else {
            // audio hemisphere (right)
            context[chatId] = context[chatId] + msg.text;
            count[chatId] = (count[chatId] ?? 0) + 1;
            if (count[chatId] % (skip[chatId] ?? 1) != 0) {
                return;
            }
            const response = await getText(context[chatId] + msg.text + ".");
            if (response) {
                context[chatId] = context[chatId] + response;
                bot.sendMessage(chatId, response);
            }
        }
    } catch (e) {
        console.error(e.message);
    }
});

const getText = async (prompt) => {
    try {
        const completion = await openai.createCompletion({
            model: "text-davinci-003",
            prompt: prompt,
            max_tokens: 1000,
            temperature: (TEMPERATURE - 36.5) / 10 + 0.5,
        });
        const response = completion.data.choices[0].text;
        console.log(response);
        return response;
    } catch (e) {
        console.error(e.message);
    }
};

const getArt = async (prompt) => {
    try {
        const response = await fetch(
            "https://api.stability.ai/v1alpha/generation/stable-diffusion-512-v2-1/text-to-image",
            {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                    Accept: "image/png",
                    Authorization: process.env.STABILITY_KEY,
                },
                body: JSON.stringify({
                    cfg_scale: 7,
                    clip_guidance_preset: "FAST_BLUE",
                    height: 512,
                    width: 512,
                    samples: 1,
                    steps: 30,
                    text_prompts: [
                        {
                            text: prompt,
                            weight: 1,
                        },
                    ],
                }),
            }
        );

        if (!response.ok) {
            console.error(`Stability-AI error: ${await response.text()}`);
            return;
        }

        return response.buffer();
    } catch (e) {
        console.error(e.message);
    }
};

const getPrompt = async (photo) => {
    const file_id = photo[photo.length - 1].file_id;
    const fileUri = await bot.getFileLink(file_id);
    const img2txt = await replicate.models.get("methexis-inc/img2prompt");
    const output = await img2txt.predict({ image: fileUri });
    return output;
};

process.env["NTBA_FIX_350"] = 1;
process.env["NODE_NO_WARNINGS"] = 1;
